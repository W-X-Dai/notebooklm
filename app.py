import gradio as gr
import fitz  # PyMuPDF
from backend import db
from backend.api import ollama_embedding
from backend.rag import rag_pipeline

"""
Gradio frontend
"""

def extract_text_from_pdf(pdf_file):
    """è®€å– PDF ä¸¦å›å‚³ç´”æ–‡å­—"""
    text = ""
    with fitz.open(pdf_file.name) as doc:
        for page in doc:
            text += page.get_text() # type: ignore
    return text


def upload_pdf(pdf_file):
    """è™•ç† PDF ä¸Šå‚³ï¼ŒæŠ½å–æ–‡å­—ä¸¦å­˜å…¥ DB"""
    if pdf_file is None:
        return "è«‹å…ˆé¸æ“‡ PDF"

    text = extract_text_from_pdf(pdf_file)

    # ç”¢ç”Ÿ embedding
    emb = ollama_embedding(text, model="nomic-embed-text:v1.5")

    # å­˜åˆ° DBï¼ˆid ç”¨æª”åï¼‰
    db.add_document(pdf_file.name, text, emb)

    return f"å·²æˆåŠŸåŠ å…¥è³‡æ–™åº«: {pdf_file.name}"


def chat(query, history):
    """RAG å•ç­”"""
    answer = rag_pipeline(query, top_k=3)
    history.append((query, answer))
    return history, ""


with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“š NotebookLM MVP\nRAG + gpt-oss + PDF ä¸Šå‚³")

    with gr.Tab("ğŸ’¬ Chat"):
        chatbot = gr.Chatbot(label="å°è©±")
        msg = gr.Textbox(label="è¼¸å…¥ä½ çš„å•é¡Œ")

        msg.submit(chat, [msg, chatbot], [chatbot, msg])

    with gr.Tab("ğŸ“‚ ä¸Šå‚³ PDF"):
        pdf_file = gr.File(label="ä¸Šå‚³ PDF", file_types=[".pdf"])
        upload_btn = gr.Button("è™•ç†ä¸¦å­˜å…¥è³‡æ–™åº«")
        output = gr.Textbox(label="çµæœ")

        upload_btn.click(upload_pdf, inputs=pdf_file, outputs=output)

demo.launch(server_name="0.0.0.0", server_port=7860)
